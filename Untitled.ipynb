{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmP11EI9mCr1NpUUSEDfJk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manamuadachi/manamuadachi.github.io/blob/master/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbv1Td0aK4Ah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "fd245881-e5ce-4cdd-ad39-c2ee6f2c1e05"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqvVhWLR9Rw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "0f4b51ef-412b-44a5-aab1-4f02ba05eead"
      },
      "source": [
        "! pip install segmentation_models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segmentation_models\n",
            "  Downloading https://files.pythonhosted.org/packages/da/b9/4a183518c21689a56b834eaaa45cad242d9ec09a4360b5b10139f23c63f4/segmentation_models-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from segmentation_models) (1.0.8)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.10.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (7.0.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (4.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.2.0)\n",
            "Installing collected packages: efficientnet, image-classifiers, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 segmentation-models-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk-kV2X99VJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import random\n",
        "from segmentation_models import Unet\n",
        "#from segmentation_models.backbones import get_preprocessing\n",
        "random.seed(1)\n",
        "\n",
        "cho=np.load(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/cho.npy\")\n",
        "cho=list(cho)\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train.csv\")\n",
        "sample_df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/sample_submission.csv\")\n",
        "\n",
        "\n",
        "\n",
        "#先頭番号\n",
        "a=[]\n",
        "#連続したラベル\n",
        "b=[]\n",
        "cho=[]\n",
        "index=0\n",
        "for i in range(3,7095-3):\n",
        "  a3=train_df.iat[i,0]\n",
        "  b3=train_df.iat[i+1,0]\n",
        "  c3=train_df.iat[i+2,0]\n",
        "  k3=[]\n",
        "  if a3!=b3 and b3==c3:\n",
        "    a.append(i)\n",
        "    k3.append(train_df.iat[i,1])\n",
        "    k3.append(train_df.iat[i,1])\n",
        "  elif b3==c3:\n",
        "    k3.append(train_df.iat[i,1])\n",
        "  elif a3==b3 and b3!=c3:\n",
        "    b.append(k3)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "#train_df(トレーニングデータフレーム)の特定の行(gyo)を入力とし、(クラスラベル,マスク行列)を出力、0がなにもない場所、1がひび割れ\n",
        "def mask(gyo):\n",
        "\ttrain=train_df.iat[gyo,2].split(\" \")\n",
        "\ttrain = [int(num) for num in train]\n",
        "\tmask = np.zeros(256*1600)\n",
        "\tmask=np.ravel(mask)\n",
        "\n",
        "\tfor i in range(int(len(train)/2)):\n",
        "\t\tmask[train[2*i]:train[2*i]+train[2*i+1]-1]=[1]*(train[2*i+1]-1)\n",
        "\tmask=mask.reshape(1600,256)\n",
        "\tmask=mask.T\n",
        "\tmask.reshape(256,1600)\n",
        "\tmask=np.array(mask)\n",
        "\treturn(train_df.iat[gyo,1],mask)\n",
        " \n",
        "\n",
        "#ランダム幾何変換関数\n",
        "def crop(A,B):\n",
        "  B0=B[0]\n",
        "  B1=B[1]\n",
        "  B2=B[2]\n",
        "  B3=B[3]\n",
        "  if random.choice([0, 1]) == 0:\n",
        "    A=cv2.flip(A,0)\n",
        "    B0=cv2.flip(B0,0)\n",
        "    B1=cv2.flip(B1,0)\n",
        "    B2=cv2.flip(B2,0)\n",
        "    B3=cv2.flip(B3,0)\n",
        "  else:\n",
        "    pass\n",
        "  if random.choice([0,1])==0:\n",
        "    A=cv2.flip(A,1)\n",
        "    B0=cv2.flip(B0,1)\n",
        "    B1=cv2.flip(B1,1)\n",
        "    B2=cv2.flip(B2,1)\n",
        "    B3=cv2.flip(B3,1)\n",
        "  else:\n",
        "    pass\n",
        "  \"\"\"\n",
        "  rows,cols,aa = A.shape\n",
        "  m1=random.choice(list(range(-5,5)))\n",
        "  m2=random.choice(list(range(-5,5)))\n",
        "  A = cv2.warpAffine(A,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B0 = cv2.warpAffine(B0,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B1 = cv2.warpAffine(B1,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B2 = cv2.warpAffine(B2,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B3 = cv2.warpAffine(B3,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  m3 = random.choice(list(range(-2,2)))\n",
        "  A = cv2.warpAffine(A,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n",
        "  B0 = cv2.warpAffine(B0,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n",
        "  B1 = cv2.warpAffine(B1,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n",
        "  B2 = cv2.warpAffine(B2,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n",
        "  B3 = cv2.warpAffine(B3,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n",
        "  ra=random.uniform(-0.1, 0.1)\n",
        "  img= np.zeros([rows,cols])\n",
        "  if random.choice([0, 1]) == 0:\n",
        "    A=np.reshape(A,(256,1600,1))\n",
        "    img=np.reshape(img,(256,1600,1))\n",
        "    for i in range(cols):\n",
        "      weight = 1+((i*ra)/cols)\n",
        "      img[:,i] = cv2.addWeighted(A[:,i],0.5*weight,A[:,i],0.5*weight,0)\n",
        "    A=img\n",
        "  else:\n",
        "    img=img.T\n",
        "    A=A.T\n",
        "    A=np.reshape(A,(1600,256,1))\n",
        "    img=np.reshape(img,(1600,256,1))\n",
        "    for i in range(rows):\n",
        "      weight = 1+((i*ra)/rows)\n",
        "      img[:,i] = cv2.addWeighted(A[:,i],0.5*weight,A[:,i],0.5*weight,0)\n",
        "    img=np.reshape(img,(256,1600))\n",
        "    A=img.T\n",
        "  \"\"\"\n",
        "  A=A*random.uniform(0.95, 1.05)\n",
        "  B=[B0,B1,B2,B3]\n",
        "  return(A,B)\n",
        "\n",
        "\n",
        "#XX入力YY出力データテンソルを作る場合のコード\n",
        "\"\"\"\n",
        "XX=[]\n",
        "YY=[]\n",
        "for i in range(データ数):\n",
        "\ty=mask(i)\n",
        "\timageid=train_df.iat[i,0]\n",
        "\tx = cv2.imread(\"C:/Users/victory adachi/pyworks/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid, cv2.IMREAD_GRAYSCALE)\n",
        "\t#x=np.array(Image.open(\"C:/Users/victory adachi/pyworks/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid))\n",
        "\tx=x/255\n",
        "\tx=np.reshape(x, (256,1600,1))\n",
        "\tX=x\n",
        "\tzeros=np.zeros([256,1600])\n",
        "\tY=[]\n",
        "\tfor j in range(4):\n",
        "\t\tif y[0]==j+1:\n",
        "\t\t\tY.append(y[1])\n",
        "\t\telse:\n",
        "\t\t\tY.append(zeros)\n",
        "\tY=np.stack(Y,2)\n",
        "\tXX.append(X)\n",
        "\tYY.append(Y)\n",
        "X_train=np.array(XX)\n",
        "Y_train=np.array(YY)\n",
        "\"\"\"\n",
        "\n",
        " \n",
        "#data generator にて入出力を作る場合のコード\n",
        "def batch_iter(data_size, batch_size):\n",
        "    data_size=int((4/5)*data_size)\n",
        "    num_batches_per_epoch = int(data_size / batch_size)\n",
        "\n",
        "    def data_generator():\n",
        "        while True:\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_index = batch_num * batch_size\n",
        "                k=random.sample(list(range(data_size)), len(list(range(data_size))) )\n",
        "                XX=[]\n",
        "                YY=[]\n",
        "                zeros=np.zeros([256,1600])\n",
        "                for i in range(batch_size):\n",
        "                \timageid=train_df.iat[k[i+start_index],0]\n",
        "\n",
        "                \ty=mask(k[i+start_index])\n",
        "                \tif k[i+start_index] in cho:\n",
        "                \t  x = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images2/\"+str(k[i+start_index])+\"_gyo.jpg\", cv2.IMREAD_GRAYSCALE)                  \n",
        "                \telse:\n",
        "                \t  x = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid, cv2.IMREAD_GRAYSCALE)\n",
        "                \tx=x/255\n",
        "                \tY=[]\n",
        "                \tfor j in range(4):\n",
        "                \t\tif y[0]==j+1:\n",
        "                \t\t\tY.append(y[1])\n",
        "                \t\telse:\n",
        "                \t\t\tY.append(zeros)\n",
        "                \t#x,Y=crop(x,Y)\n",
        "                \tx=np.reshape(x, (256,1600,1))\n",
        "                \tY=np.stack(Y,2)\n",
        "                \tXX.append(x)\n",
        "                \tYY.append(Y)\n",
        "                X_train=np.array(XX)\n",
        "                Y_train=np.array(YY)\n",
        "                yield X_train, Y_train\n",
        "    return num_batches_per_epoch, data_generator()\n",
        "#4:1で学習\n",
        "def batch_iter2(data_size, batch_size):\n",
        "    num_batches_per_epoch = int(data_size / (5*batch_size))\n",
        "    def data_generator2():\n",
        "        while True:\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_index = int((4*data_size)/5+batch_num * batch_size)\n",
        "                l0=[0]*(int((4*data_size)/5))\n",
        "                l=random.sample(list(range(int((4*data_size)/5),data_size)), len(list(range(int((4*data_size)/5),data_size))) )\n",
        "                l=l0+l\n",
        "                XX=[]\n",
        "                YY=[]\n",
        "                zeros=np.zeros([256,1600])\n",
        "                for i in range(batch_size):\n",
        "                \timageid=train_df.iat[l[i+start_index],0]\n",
        "                \ty=mask(l[i+start_index])\n",
        "                \tif l[i+start_index] in cho:\n",
        "                \t  x = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images2/\"+str(l[i+start_index])+\"_gyo.jpg\", cv2.IMREAD_GRAYSCALE)                  \n",
        "                \telse:\n",
        "                \t  x = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid, cv2.IMREAD_GRAYSCALE)\n",
        "                \tx=x/255\n",
        "                \tY=[]\n",
        "                \tfor j in range(4):\n",
        "                \t\tif y[0]==j+1:\n",
        "                \t\t\tY.append(y[1])\n",
        "                \t\telse:\n",
        "                \t\t\tY.append(zeros)\n",
        "                  \n",
        "                \t#x,Y=crop(x,Y)\n",
        "                \tx=np.reshape(x, (256,1600,1))\n",
        "                \tY=np.stack(Y,2)\n",
        "                \tXX.append(x)\n",
        "                \tYY.append(Y)\n",
        "                X_train=np.array(XX)\n",
        "                Y_train=np.array(YY)\n",
        "                yield X_train, Y_train\n",
        "    return num_batches_per_epoch, data_generator2()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#履歴\n",
        "def plot_history(history, outdir):\n",
        "    # 精度の履歴をプロット\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['dice_coef'], marker='.')\n",
        "    plt.plot(history.history['val_dice_coef'], marker='.')\n",
        "    plt.title('model dice_coef')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('dice_coef')\n",
        "    plt.grid()\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "###\n",
        "    plt.savefig(os.path.join(outdir, 'dice_coef5.png'))\n",
        "    # 損失の履歴をプロット\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'], marker='.')\n",
        "    plt.plot(history.history['val_loss'], marker='.')\n",
        "    plt.title('model loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.grid()\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "###保存\n",
        "    plt.savefig(os.path.join(outdir, 'loss5.png'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#loss func\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#model\n",
        "def build_model(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (inputs)\n",
        "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (p1)\n",
        "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (p2)\n",
        "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (p3)\n",
        "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (p4)\n",
        "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (c5)\n",
        "    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
        "\n",
        "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (p5)\n",
        "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (c55)\n",
        "\n",
        "    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n",
        "    u6 = concatenate([u6, c5])\n",
        "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (u6)\n",
        "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (c6)\n",
        "\n",
        "    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "    u71 = concatenate([u71, c4])\n",
        "    c71 = Conv2D(32, (3, 3), activation='elu', padding='same') (u71)\n",
        "    c61 = Conv2D(32, (3, 3), activation='elu', padding='same') (c71)\n",
        "\n",
        "    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (u7)\n",
        "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (u8)\n",
        "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (u9)\n",
        "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (c9)\n",
        "\n",
        "    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = build_model((256, 1600, 1))\n",
        "\"\"\"\n",
        "# LOAD UNET WITH PRETRAINING FROM IMAGENET\n",
        "#preprocess = get_preprocessing('resnet34') # for resnet, img = (img-110.0)/1.0\n",
        "model = Unet('resnet34', input_shape=(128, 800, 3), classes=4, activation='sigmoid')\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
        "\n",
        "#モデルのサマリ\n",
        "#model.summary()\n",
        "#plot_model(model, show_shapes=True, to_file='result_steel/model.png')\n",
        "\n",
        "\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n",
        "             tf.keras.callbacks.ModelCheckpoint(\n",
        "                 '../data/temp/mnist_sequential_{epoch:03d}_{val_loss:.4f}.h5',\n",
        "                 save_best_only=True\n",
        "             )]\n",
        "\"\"\"\n",
        "#history=model.fit(XX, YY, batch_size=128, epochs=7,validation_split=0.2, callbacks=callbacks)\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'model.h5', \n",
        "    monitor='val_dice_coef', \n",
        "    verbose=0, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='auto'\n",
        ")\n",
        "\n",
        "\n",
        "#学習開始\n",
        "history=model.fit_generator(batch_iter(7040, 16)[1], batch_iter(7040, 16)[0],validation_data=batch_iter2(7040,4)[1],validation_steps=batch_iter2(7040,4)[0], epochs=15,verbose=1,callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 学習履歴をプロット\n",
        "plot_history(history, '/content/drive/My Drive/kaggle_data/rireki1')\n",
        "\n",
        "###\n",
        "\n",
        "# 重みの保存\n",
        "model.save_weights('/content/drive/My Drive/kaggle_data/weight1/weights.5')\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "#evaluation\n",
        "with open('history.json', 'w') as f:\n",
        "    json.dump(history.history, f)\n",
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df[['loss', 'val_loss']].plot()\n",
        "history_df[['dice_coef', 'val_dice_coef']].plot()\n",
        "\n",
        "model.load_weights('model.h5')\n",
        "test_df = []\n",
        "\n",
        "for i in range(0, test_imgs.shape[0], 500):\n",
        "    batch_idx = list(\n",
        "        range(i, min(test_imgs.shape[0], i + 500))\n",
        "    )\n",
        "    \n",
        "    test_generator = DataGenerator(\n",
        "        batch_idx,\n",
        "        df=test_imgs,\n",
        "        shuffle=False,\n",
        "        mode='predict',\n",
        "        base_path='/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/test_images',\n",
        "        target_df=sub_df,\n",
        "        batch_size=1,\n",
        "        n_classes=4\n",
        "    )\n",
        "    batch_pred_masks = model.predict_generator(\n",
        "        test_generator, \n",
        "        workers=1,\n",
        "        verbose=1,\n",
        "        use_multiprocessing=False\n",
        "    )\n",
        "\n",
        "    for j, b in tqdm(enumerate(batch_idx)):\n",
        "        filename = test_imgs['ImageId'].iloc[b]\n",
        "        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n",
        "        \n",
        "        pred_masks = batch_pred_masks[j, ].round().astype(int)\n",
        "        pred_rles = build_rles(pred_masks)\n",
        "        \n",
        "        image_df['EncodedPixels'] = pred_rles\n",
        "        test_df.append(image_df)\n",
        "\n",
        "test_df = pd.concat(test_df)\n",
        "test_df.drop(columns='ImageId', inplace=True)\n",
        "test_df.to_csv('submission.csv', index=False)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "                \tif k[i+start_index] in a:\n",
        "                \t  x = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid, cv2.IMREAD_GRAYSCALE)\n",
        "                \t  x=x/255\n",
        "                \t  num=a.index(k[i+start_index])\n",
        "                \t  Y=[]\n",
        "                \t  for j in [1,2,3,4]:\n",
        "                \t    if j in b[num]:\n",
        "                \t      Y.apped(mask(k[i+start_index]+b[num].index(j))[0])\n",
        "                \t    else:\n",
        "                \t      Y.append(zeros)\n",
        "                \t  x,Y=crop(x,Y)\n",
        "                \t  x=np.reshape(x, (256,1600,1))\n",
        "                \t  Y=np.stack(Y,2)\n",
        "                \t  XX.append(x)\n",
        "                \t  YY.append(Y)\n",
        "                \telse:\n",
        "                \t  pass\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "                \tif l[i+start_index] in a:\n",
        "                \t  x = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid, cv2.IMREAD_GRAYSCALE)\n",
        "                \t  x=x/255\n",
        "                \t  num=a.index(l[i+start_index])\n",
        "                \t  Y=[]\n",
        "                \t  for j in [1,2,3,4]:\n",
        "                \t    if j in b[num]:\n",
        "                \t      Y.apped(mask(l[i+start_index]+b[num].index(j))[0])\n",
        "                \t    else:\n",
        "                \t      Y.append(zeros)\n",
        "                \t  x,Y=crop(x,Y)\n",
        "                \t  x=np.reshape(x, (256,1600,1))\n",
        "                \t  Y=np.stack(Y,2)\n",
        "                \t  XX.append(x)\n",
        "                \t  YY.append(Y)\n",
        "                \telse:\n",
        "                \t  pass\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaSojtXi_OhD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "44b0df52-03d5-4642-fa0a-4c7ffa75926e"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import random\n",
        "from segmentation_models import Unet\n",
        "#from segmentation_models.backbones import get_preprocessing\n",
        "random.seed(1)\n",
        "\n",
        "cho=np.load(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/cho.npy\")\n",
        "cho=list(cho)\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train.csv\")\n",
        "sample_df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/sample_submission.csv\")\n",
        "\n",
        "nume=0\n",
        "\"\"\"\n",
        "epoval=[0,200,400,600,800]\n",
        "x = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/0002cc93b.jpg\")\n",
        "\n",
        "x = x[0 : 256, epoval[nume%5]: epoval[nume%5]+400]\n",
        "print(x.shape)\n",
        "\"\"\"\n",
        "\n",
        "#train_df(トレーニングデータフレーム)の特定の行(gyo)を入力とし、(クラスラベル,マスク行列)を出力、0がなにもない場所、1がひび割れ\n",
        "def mask(gyo):\n",
        "\ttrain=train_df.iat[gyo,2].split(\" \")\n",
        "\ttrain = [int(num) for num in train]\n",
        "\tmask = np.zeros(256*1600)\n",
        "\tmask=np.ravel(mask)\n",
        "\n",
        "\tfor i in range(int(len(train)/2)):\n",
        "\t\tmask[train[2*i]:train[2*i]+train[2*i+1]-1]=[1]*(train[2*i+1]-1)\n",
        "\tmask=mask.reshape(1600,256)\n",
        "\tmask=mask.T\n",
        "\tmask.reshape(256,1600)\n",
        "\tmask=np.array(mask)\n",
        "\treturn(train_df.iat[gyo,1],mask)\n",
        " \n",
        "\n",
        "#ランダム幾何変換関数\n",
        "def crop(A,B):\n",
        "  B0=B[0]\n",
        "  B1=B[1]\n",
        "  B2=B[2]\n",
        "  B3=B[3]\n",
        "  if (nume//4)%4 == 1 or 3:\n",
        "    A=cv2.flip(A,0)\n",
        "    B0=cv2.flip(B0,0)\n",
        "    B1=cv2.flip(B1,0)\n",
        "    B2=cv2.flip(B2,0)\n",
        "    B3=cv2.flip(B3,0)\n",
        "  else:\n",
        "    pass\n",
        "  if (nume//4)%4 == 2 or 3:\n",
        "    A=cv2.flip(A,1)\n",
        "    B0=cv2.flip(B0,1)\n",
        "    B1=cv2.flip(B1,1)\n",
        "    B2=cv2.flip(B2,1)\n",
        "    B3=cv2.flip(B3,1)\n",
        "  else:\n",
        "    pass\n",
        "  \"\"\"\n",
        "  rows,cols,aa = A.shape\n",
        "  m1=random.choice(list(range(-5,5)))\n",
        "  m2=random.choice(list(range(-5,5)))\n",
        "  A = cv2.warpAffine(A,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B0 = cv2.warpAffine(B0,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B1 = cv2.warpAffine(B1,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B2 = cv2.warpAffine(B2,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B3 = cv2.warpAffine(B3,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  m3 = random.choice(list(range(-2,2)))\n",
        "  A = cv2.warpAffine(A,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n",
        "  B0 = cv2.warpAffine(B0,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n",
        "  B1 = cv2.warpAffine(B1,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n",
        "  B2 = cv2.warpAffine(B2,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n",
        "  B3 = cv2.warpAffine(B3,cv2.getRotationMatrix2D((cols/2,rows/2),m3,1),(cols,rows))\n",
        "  ra=random.uniform(-0.1, 0.1)\n",
        "  img= np.zeros([rows,cols])\n",
        "  if random.choice([0, 1]) == 0:\n",
        "    A=np.reshape(A,(256,1600,1))\n",
        "    img=np.reshape(img,(256,1600,1))\n",
        "    for i in range(cols):\n",
        "      weight = 1+((i*ra)/cols)\n",
        "      img[:,i] = cv2.addWeighted(A[:,i],0.5*weight,A[:,i],0.5*weight,0)\n",
        "    A=img\n",
        "  else:\n",
        "    img=img.T\n",
        "    A=A.T\n",
        "    A=np.reshape(A,(1600,256,1))\n",
        "    img=np.reshape(img,(1600,256,1))\n",
        "    for i in range(rows):\n",
        "      weight = 1+((i*ra)/rows)\n",
        "      img[:,i] = cv2.addWeighted(A[:,i],0.5*weight,A[:,i],0.5*weight,0)\n",
        "    img=np.reshape(img,(256,1600))\n",
        "    A=img.T\n",
        "  \"\"\"\n",
        "  #A=A*random.uniform(0.95, 1.05)\n",
        "  B=[B0,B1,B2,B3]\n",
        "  return(A,B)\n",
        "\n",
        "\n",
        "epoval=[0,362,726,1088]\n",
        "\n",
        " \n",
        "#data generator にて入出力を作る場合のコード\n",
        "def batch_iter(data_size, batch_size):\n",
        "    data_size=int((4/5)*data_size)\n",
        "    num_batches_per_epoch = int(data_size / batch_size)\n",
        "\n",
        "    def data_generator():\n",
        "        while True:\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_index = batch_num * batch_size\n",
        "                global nume\n",
        "                if start_index==0:\n",
        "                  nume=nume+1\n",
        "                else:\n",
        "                  pass\n",
        "                k=random.sample(list(range(data_size)), len(list(range(data_size))) )\n",
        "                XX=[]\n",
        "                YY=[]\n",
        "                zeros=np.zeros([256,512])\n",
        "                for i in range(batch_size):\n",
        "                \timageid=train_df.iat[k[i+start_index],0]\n",
        "\n",
        "                \ty=mask(k[i+start_index])\n",
        "                \tif k[i+start_index] in cho:\n",
        "                \t  x = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images2/\"+str(k[i+start_index])+\"_gyo.jpg\")                  \n",
        "                \telse:\n",
        "                \t  x = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid)\n",
        "\n",
        "                \tx=x/255\n",
        "                \tx = x[0 : 256, epoval[nume%3]: epoval[nume%3]+512]\n",
        "                \tY=[]\n",
        "                \tfor j in range(4):\n",
        "                \t\tif y[0]==j+1:\n",
        "                \t\t\tY.append(y[1][0 : 256, epoval[nume%4]: epoval[nume%4]+512])\n",
        "                \t\telse:\n",
        "                \t\t\tY.append(zeros)\n",
        "                \tx,Y=crop(x,Y)\n",
        "                \t#x=np.reshape(x, (256,1600,1))\n",
        "                \tY=np.stack(Y,2)\n",
        "                \tXX.append(x)\n",
        "                \tYY.append(Y)\n",
        "                X_train=np.array(XX)\n",
        "                Y_train=np.array(YY)\n",
        "                yield X_train, Y_train\n",
        "    return num_batches_per_epoch, data_generator()\n",
        "#4:1で学習\n",
        "def batch_iter2(data_size, batch_size):\n",
        "    num_batches_per_epoch = int(data_size / (5*batch_size))\n",
        "    def data_generator2():\n",
        "        while True:\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_index = int((4*data_size)/5+batch_num * batch_size)\n",
        "                l0=[0]*(int((4*data_size)/5))\n",
        "                l=random.sample(list(range(int((4*data_size)/5),data_size)), len(list(range(int((4*data_size)/5),data_size))) )\n",
        "                l=l0+l\n",
        "                XX=[]\n",
        "                YY=[]\n",
        "                zeros=np.zeros([256,512])\n",
        "                for i in range(batch_size):\n",
        "                \timageid=train_df.iat[l[i+start_index],0]\n",
        "                \ty=mask(l[i+start_index])\n",
        "                \tif l[i+start_index] in cho:\n",
        "                \t  x = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images2/\"+str(l[i+start_index])+\"_gyo.jpg\")                  \n",
        "                \telse:\n",
        "                \t  x = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid)\n",
        "                \tx=x[0 : 256, epoval[nume%3]: epoval[nume%3]+512]\n",
        "                \tx=x/255\n",
        "                \tY=[]\n",
        "                \tfor j in range(4):\n",
        "                \t\tif y[0]==j+1:\n",
        "                \t\t\tY.append(y[1][0 : 256, epoval[nume%3]: epoval[nume%3]+512])\n",
        "                \t\telse:\n",
        "                \t\t\tY.append(zeros)\n",
        "                  \n",
        "                \tx,Y=crop(x,Y)\n",
        "                \t#x=np.reshape(x, (256,1600,1))\n",
        "                \tY=np.stack(Y,2)\n",
        "                \tXX.append(x)\n",
        "                \tYY.append(Y)\n",
        "                X_train=np.array(XX)\n",
        "                Y_train=np.array(YY)\n",
        "                yield X_train, Y_train\n",
        "    return num_batches_per_epoch, data_generator2()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#履歴\n",
        "def plot_history(history, outdir):\n",
        "    # 精度の履歴をプロット\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['dice_coef'], marker='.')\n",
        "    plt.plot(history.history['val_dice_coef'], marker='.')\n",
        "    plt.title('model dice_coef')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('dice_coef')\n",
        "    plt.grid()\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "###\n",
        "    plt.savefig(os.path.join(outdir, 'dice_coef4.png'))\n",
        "    # 損失の履歴をプロット\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'], marker='.')\n",
        "    plt.plot(history.history['val_loss'], marker='.')\n",
        "    plt.title('model loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.grid()\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "###保存\n",
        "    plt.savefig(os.path.join(outdir, 'loss4.png'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#loss func\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# LOAD UNET WITH PRETRAINING FROM IMAGENET\n",
        "#preprocess = get_preprocessing('resnet34') # for resnet, img = (img-110.0)/1.0\n",
        "model = Unet('resnet34', input_shape=(256, 512, 3), classes=4, activation='sigmoid')\n",
        "model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n",
        "\n",
        "#モデルのサマリ\n",
        "#model.summary()\n",
        "#plot_model(model, show_shapes=True, to_file='result_steel/model.png')\n",
        "\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'model.h5', \n",
        "    monitor='val_dice_coef', \n",
        "    verbose=0, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='auto'\n",
        ")\n",
        "def numepo():\n",
        "  nume=nume+1\n",
        "\n",
        "#学習開始\n",
        "history=model.fit_generator(batch_iter(7040, 16)[1], batch_iter(7040, 16)[0],validation_data=batch_iter2(7040,4)[1],validation_steps=batch_iter2(7040,4)[0], epochs=30,verbose=1,callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 学習履歴をプロット\n",
        "plot_history(history, '/content/drive/My Drive/kaggle_data/rireki1')\n",
        "\n",
        "###\n",
        "\n",
        "# 重みの保存\n",
        "model.save_weights('/content/drive/My Drive/kaggle_data/weight1/weights.4')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "352/352 [==============================] - 2636s 7s/step - loss: 0.7165 - dice_coef: 0.3805 - val_loss: 1.0596 - val_dice_coef: 9.2663e-04\n",
            "Epoch 2/30\n",
            "352/352 [==============================] - 1086s 3s/step - loss: 0.5134 - dice_coef: 0.5515 - val_loss: 1.0869 - val_dice_coef: 0.0158\n",
            "Epoch 3/30\n",
            "352/352 [==============================] - 649s 2s/step - loss: 0.9832 - dice_coef: 0.0985 - val_loss: 1.1468 - val_dice_coef: 0.1045\n",
            "Epoch 4/30\n",
            "352/352 [==============================] - 596s 2s/step - loss: 0.9252 - dice_coef: 0.1543 - val_loss: 0.6270 - val_dice_coef: 0.1417\n",
            "Epoch 5/30\n",
            "352/352 [==============================] - 588s 2s/step - loss: 0.9065 - dice_coef: 0.1841 - val_loss: 1.0928 - val_dice_coef: 0.1322\n",
            "Epoch 6/30\n",
            "352/352 [==============================] - 581s 2s/step - loss: 0.9441 - dice_coef: 0.1499 - val_loss: 1.0581 - val_dice_coef: 0.1163\n",
            "Epoch 7/30\n",
            "352/352 [==============================] - 581s 2s/step - loss: 0.9515 - dice_coef: 0.1238 - val_loss: 0.9994 - val_dice_coef: 0.1140\n",
            "Epoch 8/30\n",
            "352/352 [==============================] - 580s 2s/step - loss: 0.9328 - dice_coef: 0.1483 - val_loss: 1.1545 - val_dice_coef: 0.1150\n",
            "Epoch 9/30\n",
            "352/352 [==============================] - 582s 2s/step - loss: 0.8962 - dice_coef: 0.1932 - val_loss: 1.0289 - val_dice_coef: 0.1106\n",
            "Epoch 10/30\n",
            "352/352 [==============================] - 582s 2s/step - loss: 0.9038 - dice_coef: 0.1856 - val_loss: 1.0125 - val_dice_coef: 0.1373\n",
            "Epoch 11/30\n",
            "352/352 [==============================] - 582s 2s/step - loss: 0.8737 - dice_coef: 0.2009 - val_loss: 1.0506 - val_dice_coef: 0.0625\n",
            "Epoch 12/30\n",
            "352/352 [==============================] - 582s 2s/step - loss: 0.7146 - dice_coef: 0.3511 - val_loss: 1.0028 - val_dice_coef: 0.2941\n",
            "Epoch 13/30\n",
            "319/352 [==========================>...] - ETA: 49s - loss: 0.5857 - dice_coef: 0.4825"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvXQAgUcgKEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "3d02745a-1153-44e5-e772-4605553d8eb8"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "#画像の一部を表示するようにカット\n",
        "#画像、マスクのペアを生成、マスクがゼロの場合は保存しない\n",
        "cho=np.load(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/cho.npy\")\n",
        "cho=list(cho)\n",
        "train_df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train.csv\")\n",
        "\n",
        "\n",
        "#train_df(トレーニングデータフレーム)の特定の行(gyo)を入力とし、(クラスラベル,マスク行列)を出力、0がなにもない場所、1がひび割れ\n",
        "def mask(gyo):\n",
        "\ttrain=train_df.iat[gyo,2].split(\" \")\n",
        "\ttrain = [int(num) for num in train]\n",
        "\tmask = np.zeros(256*1600)\n",
        "\tmask=np.ravel(mask)\n",
        "\tfor i in range(int(len(train)/2)):\n",
        "\t\tmask[train[2*i]:train[2*i]+train[2*i+1]-1]=[1]*(train[2*i+1]-1)\n",
        "\tmask=mask.reshape(1600,256)\n",
        "\tmask=mask.T\n",
        "\tmask.reshape(256,1600)\n",
        "\tmask=np.array(mask)\n",
        "\treturn(train_df.iat[gyo,1],mask)\n",
        "kk=[]\n",
        "ll=[]\n",
        "zeros=np.zeros([256,512])\n",
        "p=0\n",
        "#マスクの読み込み\n",
        "for i in range(7095):\n",
        "  for j in [0,362,726,1088]:\n",
        "    masks=mask(i)[1][0:256,j:j+512]\n",
        "    if np.sum(masks)<140:\n",
        "      pass\n",
        "#マスク、イメージ保存\n",
        "    else:\n",
        "      #np.save(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/tramas/\"+str(p)+\"mask\",masks)\n",
        "      #if i in cho:\n",
        "      #  img = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images2/\"+str(i)+\"_gyo.jpg\")\n",
        "      #else:\n",
        "      #  img=cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+train_df.iat[i,0])\n",
        "      #img=img[0:256,j:j+512]\n",
        "      #cv2.imwrite(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/tra/\"+str(p)+\"img.jpg\",img)\n",
        "      #p=p+1\n",
        "      kk.append(train_df.iat[i,1])\n",
        "      ll.append([i,j])\n",
        "  if i%500==0:\n",
        "    print(i)\n",
        "  else:\n",
        "    pass\n",
        "kk=np.array(kk)\n",
        "print(kk)\n",
        "np.save(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/masklabel\",kk)\n",
        "np.save(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/maskno\",ll)    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "500\n",
            "1000\n",
            "1500\n",
            "2000\n",
            "2500\n",
            "3000\n",
            "3500\n",
            "4000\n",
            "4500\n",
            "5000\n",
            "5500\n",
            "6000\n",
            "6500\n",
            "7000\n",
            "[1 1 1 ... 3 3 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmBGESmZaOEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "for i in range(14000):\n",
        "  if os.path.exists(\"/content/drive/My Drive/\"+str(i)+\"mask.npy\"):\n",
        "    os.unlink(\"/content/drive/My Drive/\"+str(i)+\"mask.npy\")\n",
        "  else:\n",
        "    pass\n",
        "  if os.path.exists(\"/content/drive/My Drive/\"+str(i)+\"img.jpg\"):\n",
        "    os.unlink(\"/content/drive/My Drive/\"+str(i)+\"img.jpg\")\n",
        "  if i%1000==0:\n",
        "    print(i)\n",
        "  else:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZdkm6S6s-GW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "4023c491-f6d5-4b1a-8d72-63fd72ceffa3"
      },
      "source": [
        "#ResNetUnet\n",
        "\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import random\n",
        "from segmentation_models import Unet\n",
        "#from segmentation_models.backbones import get_preprocessing\n",
        "random.seed(1)\n",
        "\n",
        "cho=np.load(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/cho.npy\")\n",
        "cho=list(cho)\n",
        "train_df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train.csv\")\n",
        "\n",
        "nume=0\n",
        "masklabel=np.load(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/masklabel.npy\")\n",
        "maskno=np.load(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/maskno.npy\")\n",
        "\n",
        "def mask(gyo):\n",
        "\ttrain=train_df.iat[gyo,2].split(\" \")\n",
        "\ttrain = [int(num) for num in train]\n",
        "\tmask = np.zeros(256*1600)\n",
        "\tmask=np.ravel(mask)\n",
        "\tfor i in range(int(len(train)/2)):\n",
        "\t\tmask[train[2*i]:train[2*i]+train[2*i+1]-1]=[1]*(train[2*i+1]-1)\n",
        "\tmask=mask.reshape(1600,256)\n",
        "\tmask=mask.T\n",
        "\tmask.reshape(256,1600)\n",
        "\tmask=np.array(mask)\n",
        "\treturn(train_df.iat[gyo,1],mask)\n",
        "\n",
        "#ランダム幾何変換関数\n",
        "def crop(A,B):\n",
        "  B0=B[0]\n",
        "  B1=B[1]\n",
        "  B2=B[2]\n",
        "  B3=B[3]\n",
        "\n",
        "  if (nume)%2 == 1:\n",
        "    A=cv2.flip(A,1)\n",
        "    B0=cv2.flip(B0,1)\n",
        "    B1=cv2.flip(B1,1)\n",
        "    B2=cv2.flip(B2,1)\n",
        "    B3=cv2.flip(B3,1)\n",
        "  else:\n",
        "    pass\n",
        "  rows,cols,aa = A.shape\n",
        "  \"\"\"\n",
        "  m1=random.choice(list(range(-10,10)))\n",
        "  m2=0\n",
        "  A = cv2.warpAffine(A,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B0 = cv2.warpAffine(B0,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B1 = cv2.warpAffine(B1,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B2 = cv2.warpAffine(B2,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B3 = cv2.warpAffine(B3,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  m3 = random.choice(list(range(-2,2)))\n",
        "  \"\"\"\n",
        "  A=A*random.uniform(0.95, 1.05)\n",
        "  B=[B0,B1,B2,B3]\n",
        "  return(A,B)\n",
        "\n",
        "\n",
        " \n",
        "#data generator にて入出力を作る場合のコード\n",
        "def batch_iter(data_size, batch_size):\n",
        "    data_size=int((4/5)*data_size)\n",
        "    num_batches_per_epoch = int(data_size / batch_size)\n",
        "\n",
        "    def data_generator():\n",
        "        while True:\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_index = batch_num * batch_size\n",
        "                global nume\n",
        "                if start_index==0:\n",
        "                  nume=nume+1\n",
        "                else:\n",
        "                  pass\n",
        "                \n",
        "                k=random.sample(list(range(data_size)), len(list(range(data_size))) )\n",
        "                XX=[]\n",
        "                YY=[]\n",
        "                zeros=np.zeros([256,512])\n",
        "                for i in range(batch_size):\n",
        "                \timageid=k[i+start_index]\n",
        "                \ty=mask(maskno[imageid][0])[1]\n",
        "#                  if maskno[imageid][0] in cho:\n",
        "#                    y = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images2/\"+str(maskno[imageid][0])+\"_gyo.jpg\") \n",
        "#                  else:\n",
        "#                  \ty = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+train_df.iat[maskno[imageid][0],0])                \n",
        "                \ty=y[0:256,maskno[imageid][1]:maskno[imageid][1]+512]\n",
        "                \tx = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/tra/\"+str(imageid)+\"img.jpg\")\n",
        "\n",
        "                \tx=x/255\n",
        "                \tY=[]\n",
        "                \tfor j in range(4):\n",
        "                \t\tif masklabel[imageid]==j+1:\n",
        "                \t\t\tY.append(y)\n",
        "                \t\telse:\n",
        "                \t\t\tY.append(zeros)\n",
        "                \tx,Y=crop(x,Y)\n",
        "                \tY=np.stack(Y,2)\n",
        "                \tXX.append(x)\n",
        "                \tYY.append(Y)\n",
        "                X_train=np.array(XX)\n",
        "                Y_train=np.array(YY)\n",
        "                yield X_train, Y_train\n",
        "    return num_batches_per_epoch, data_generator()\n",
        "#4:1で学習\n",
        "def batch_iter2(data_size, batch_size):\n",
        "    num_batches_per_epoch = int(data_size / (5*batch_size))\n",
        "    def data_generator2():\n",
        "        while True:\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_index = int((4*data_size)/5+batch_num * batch_size)\n",
        "                l0=[0]*(int((4*data_size)/5))\n",
        "                l=random.sample(list(range(int((4*data_size)/5),data_size)), len(list(range(int((4*data_size)/5),data_size))) )\n",
        "                l=l0+l\n",
        "                XX=[]\n",
        "                YY=[]\n",
        "                zeros=np.zeros([256,512])\n",
        "                for i in range(batch_size):\n",
        "                \timageid=l[i+start_index]\n",
        "                \ty=mask(maskno[imageid][0])[1]\n",
        "#                  if maskno[imageid][0] in cho:\n",
        "#                    y = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images2/\"+str(maskno[imageid][0])+\"_gyo.jpg\") \n",
        "#                  else:\n",
        "#                  \ty = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+train_df.iat[maskno[imageid][0],0])                \n",
        "                \ty=y[0:256,maskno[imageid][1]:maskno[imageid][1]+512]                 \n",
        "\n",
        "                \tx = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/tra/\"+str(imageid)+\"img.jpg\")\n",
        "\n",
        "                \tx=x/255\n",
        "                \tY=[]\n",
        "                \tfor j in range(4):\n",
        "                \t\tif masklabel[imageid]==j+1:\n",
        "                \t\t\tY.append(y)\n",
        "                \t\telse:\n",
        "                \t\t\tY.append(zeros)\n",
        "                \tx,Y=crop(x,Y)\n",
        "                \tY=np.stack(Y,2)\n",
        "                \tXX.append(x)\n",
        "                \tYY.append(Y)\n",
        "                X_train=np.array(XX)\n",
        "                Y_train=np.array(YY)\n",
        "                yield X_train, Y_train\n",
        "    return num_batches_per_epoch, data_generator2()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#履歴\n",
        "def plot_history(history, outdir):\n",
        "    # 精度の履歴をプロット\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['dice_coef'], marker='.')\n",
        "    plt.plot(history.history['val_dice_coef'], marker='.')\n",
        "    plt.title('model dice_coef')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('dice_coef')\n",
        "    plt.grid()\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "###\n",
        "    plt.savefig(os.path.join(outdir, 'dice_coef5.png'))\n",
        "    # 損失の履歴をプロット\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'], marker='.')\n",
        "    plt.plot(history.history['val_loss'], marker='.')\n",
        "    plt.title('model loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.grid()\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "###保存\n",
        "    plt.savefig(os.path.join(outdir, 'loss5.png'))\n",
        "\n",
        "#loss func\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "model = Unet('resnet34', input_shape=(256, 512, 3), classes=4, activation='sigmoid')\n",
        "model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n",
        "###\n",
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/drive/My Drive/kaggle_data/weightlog/weight5model.h5', \n",
        "    monitor='val_dice_coef', \n",
        "    verbose=0, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='auto'\n",
        ")\n",
        "def numepo():\n",
        "  nume=nume+1\n",
        "\n",
        "#学習開始\n",
        "history=model.fit_generator(batch_iter(15840, 16)[1], batch_iter(15840, 16)[0],validation_data=batch_iter2(15840,4)[1],validation_steps=batch_iter2(15840,4)[0], epochs=12,verbose=1,callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 学習履歴をプロット\n",
        "plot_history(history, '/content/drive/My Drive/kaggle_data/rireki1')\n",
        "\n",
        "###\n",
        "\n",
        "# 重みの保存\n",
        "model.save_weights('/content/drive/My Drive/kaggle_data/weight1/weights.5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n",
            "Epoch 1/2\n",
            " 39/792 [>.............................] - ETA: 10:04:15 - loss: 1.0662 - dice_coef: 0.1528"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0a6b32c40587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;31m#学習開始\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15840\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15840\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_iter2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15840\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_iter2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15840\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbP_gSNKjk0Y",
        "colab_type": "text"
      },
      "source": [
        "# 新しいセクション"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu6KJkX9l63X",
        "colab_type": "text"
      },
      "source": [
        "Epoch 1/30\n",
        "792/792 [==============================] - 8141s 10s/step - loss: 0.5600 - dice_coef: 0.5335 - val_loss: 1.2396 - val_dice_coef: 0.0221\n",
        "Epoch 2/30\n",
        "792/792 [==============================] - 3311s 4s/step - loss: 0.4474 - dice_coef: 0.6271 - val_loss: 0.3080 - val_dice_coef: 0.5997\n",
        "Epoch 3/30\n",
        "792/792 [==============================] - 1631s 2s/step - loss: 0.4077 - dice_coef: 0.6598 - val_loss: 0.5868 - val_dice_coef: 0.5866\n",
        "Epoch 4/30\n",
        "792/792 [==============================] - 1401s 2s/step - loss: 0.3875 - dice_coef: 0.6770 - val_loss: 0.3312 - val_dice_coef: 0.6142\n",
        "Epoch 5/30\n",
        "792/792 [==============================] - 1342s 2s/step - loss: 0.3820 - dice_coef: 0.6818 - val_loss: 0.2441 - val_dice_coef: 0.6443\n",
        "Epoch 6/30\n",
        "792/792 [==============================] - 1342s 2s/step - loss: 0.3642 - dice_coef: 0.6952 - val_loss: 0.3619 - val_dice_coef: 0.6692\n",
        "Epoch 7/30\n",
        "792/792 [==============================] - 1329s 2s/step - loss: 0.3588 - dice_coef: 0.6994 - val_loss: 0.4246 - val_dice_coef: 0.6601\n",
        "Epoch 8/30\n",
        "792/792 [==============================] - 1333s 2s/step - loss: 0.3532 - dice_coef: 0.7044 - val_loss: 0.1917 - val_dice_coef: 0.6643\n",
        "Epoch 9/30\n",
        "792/792 [==============================] - 1326s 2s/step - loss: 0.3415 - dice_coef: 0.7144 - val_loss: 0.4643 - val_dice_coef: 0.6473\n",
        "Epoch 10/30\n",
        "792/792 [==============================] - 1328s 2s/step - loss: 0.3354 - dice_coef: 0.7193 - val_loss: 0.2961 - val_dice_coef: 0.6684\n",
        "Epoch 11/30\n",
        "792/792 [==============================] - 1323s 2s/step - loss: 0.3227 - dice_coef: 0.7295 - val_loss: 0.1907 - val_dice_coef: 0.6734\n",
        "Epoch 12/30\n",
        "792/792 [==============================] - 1322s 2s/step - loss: 0.3326 - dice_coef: 0.7217 - val_loss: 0.4045 - val_dice_coef: 0.6081\n",
        "Epoch 13/30\n",
        "792/792 [==============================] - 1321s 2s/step - loss: 0.3238 - dice_coef: 0.7285 - val_loss: 0.1423 - val_dice_coef: 0.6689\n",
        "Epoch 14/30\n",
        "792/792 [==============================] - 1323s 2s/step - loss: 0.3045 - dice_coef: 0.7447 - val_loss: 0.2167 - val_dice_coef: 0.6883\n",
        "Epoch 15/30\n",
        "792/792 [==============================] - 1321s 2s/step - loss: 0.3145 - dice_coef: 0.7359 - val_loss: 0.1867 - val_dice_coef: 0.6887\n",
        "Epoch 16/30\n",
        "792/792 [==============================] - 1324s 2s/step - loss: 0.3076 - dice_coef: 0.7418 - val_loss: 0.2546 - val_dice_coef: 0.6876\n",
        "Epoch 17/30\n",
        "667/792 [========================>.....] - ETA: 3:10 - loss: 0.2982 - dice_coef: 0.7502"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ALW07iEBEoDR",
        "colab": {}
      },
      "source": [
        "#Unet224*480\n",
        "\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import random\n",
        "from segmentation_models import Unet\n",
        "#from segmentation_models.backbones import get_preprocessing\n",
        "random.seed(1)\n",
        "\n",
        "cho=np.load(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/cho.npy\")\n",
        "cho=list(cho)\n",
        "\n",
        "nume=0\n",
        "masklabel=np.load(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/masklabel.npy\")\n",
        "\n",
        "#ランダム幾何変換関数\n",
        "def crop(A,B):\n",
        "  B0=B[0]\n",
        "  B1=B[1]\n",
        "  B2=B[2]\n",
        "  B3=B[3]\n",
        "\n",
        "  if (nume)%2 == 1:\n",
        "    A=cv2.flip(A,1)\n",
        "    B0=cv2.flip(B0,1)\n",
        "    B1=cv2.flip(B1,1)\n",
        "    B2=cv2.flip(B2,1)\n",
        "    B3=cv2.flip(B3,1)\n",
        "  else:\n",
        "    pass\n",
        "  m1=random.choice(list(range(0,32)))\n",
        "  m2=random.choice(list(range(0,32)))\n",
        "  A=A[m1 : m1+224, m2: m2+480]\n",
        "  rows,cols,aa = A.shape\n",
        "  \"\"\"\n",
        "  m1=random.choice(list(range(-10,10)))\n",
        "  m2=0\n",
        "  A = cv2.warpAffine(A,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B0 = cv2.warpAffine(B0,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B1 = cv2.warpAffine(B1,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B2 = cv2.warpAffine(B2,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B3 = cv2.warpAffine(B3,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  m3 = random.choice(list(range(-2,2)))\n",
        "  \"\"\"\n",
        "  A=A*random.uniform(0.95, 1.05)\n",
        "  B=[B0,B1,B2,B3]\n",
        "  return(A,B)\n",
        "\n",
        "\n",
        " \n",
        "#data generator にて入出力を作る場合のコード\n",
        "def batch_iter(data_size, batch_size):\n",
        "    data_size=int((4/5)*data_size)\n",
        "    num_batches_per_epoch = int(data_size / batch_size)\n",
        "\n",
        "    def data_generator():\n",
        "        while True:\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_index = batch_num * batch_size\n",
        "                global nume\n",
        "                if start_index==0:\n",
        "                  nume=nume+1\n",
        "                else:\n",
        "                  pass\n",
        "                \n",
        "                k=random.sample(list(range(data_size)), len(list(range(data_size))) )\n",
        "                XX=[]\n",
        "                YY=[]\n",
        "                zeros=np.zeros([256,512])\n",
        "                for i in range(batch_size):\n",
        "                \timageid=k[i+start_index]\n",
        "\n",
        "                \ty=np.load(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/tramas/\"+str(imageid)+\"mask.npy\")\n",
        "                \tx = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/tra/\"+str(imageid)+\"img.jpg\")\n",
        "\n",
        "                \tx=x/255\n",
        "                \tY=[]\n",
        "                \tfor j in range(4):\n",
        "                \t\tif masklabel[imageid]==j+1:\n",
        "                \t\t\tY.append(y)\n",
        "                \t\telse:\n",
        "                \t\t\tY.append(zeros)\n",
        "                \tx,Y=crop(x,Y)\n",
        "                \tY=np.stack(Y,2)\n",
        "                \tXX.append(x)\n",
        "                \tYY.append(Y)\n",
        "                X_train=np.array(XX)\n",
        "                Y_train=np.array(YY)\n",
        "                yield X_train, Y_train\n",
        "    return num_batches_per_epoch, data_generator()\n",
        "#4:1で学習\n",
        "def batch_iter2(data_size, batch_size):\n",
        "    num_batches_per_epoch = int(data_size / (5*batch_size))\n",
        "    def data_generator2():\n",
        "        while True:\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_index = int((4*data_size)/5+batch_num * batch_size)\n",
        "                l0=[0]*(int((4*data_size)/5))\n",
        "                l=random.sample(list(range(int((4*data_size)/5),data_size)), len(list(range(int((4*data_size)/5),data_size))) )\n",
        "                l=l0+l\n",
        "                XX=[]\n",
        "                YY=[]\n",
        "                zeros=np.zeros([256,512])\n",
        "                for i in range(batch_size):\n",
        "                \timageid=l[i+start_index]\n",
        "                \ty=np.load(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/tra/\"+str(imageid)+\"mask.npy\")\n",
        "                \tx = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/tra/\"+str(imageid)+\"img.jpg\")\n",
        "\n",
        "                \tx=x/255\n",
        "                \tY=[]\n",
        "                \tfor j in range(4):\n",
        "                \t\tif masklabel[imageid]==j+1:\n",
        "                \t\t\tY.append(y)\n",
        "                \t\telse:\n",
        "                \t\t\tY.append(zeros)\n",
        "                \tx,Y=crop(x,Y)\n",
        "                \tY=np.stack(Y,2)\n",
        "                \tXX.append(x)\n",
        "                \tYY.append(Y)\n",
        "                X_train=np.array(XX)\n",
        "                Y_train=np.array(YY)\n",
        "                yield X_train, Y_train\n",
        "    return num_batches_per_epoch, data_generator2()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#履歴\n",
        "def plot_history(history, outdir):\n",
        "    # 精度の履歴をプロット\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['dice_coef'], marker='.')\n",
        "    plt.plot(history.history['val_dice_coef'], marker='.')\n",
        "    plt.title('model dice_coef')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('dice_coef')\n",
        "    plt.grid()\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "###\n",
        "    plt.savefig(os.path.join(outdir, 'dice_coef6.png'))\n",
        "    # 損失の履歴をプロット\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'], marker='.')\n",
        "    plt.plot(history.history['val_loss'], marker='.')\n",
        "    plt.title('model loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.grid()\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "###保存\n",
        "    plt.savefig(os.path.join(outdir, 'loss6.png'))\n",
        "\n",
        "#loss func\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "model = Unet('resnet34', input_shape=(224, 480, 3), classes=4, activation='sigmoid')\n",
        "model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=[dice_coef])\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'model.h5', \n",
        "    monitor='val_dice_coef', \n",
        "    verbose=0, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='auto'\n",
        ")\n",
        "def numepo():\n",
        "  nume=nume+1\n",
        "\n",
        "#学習開始\n",
        "history=model.fit_generator(batch_iter(15840, 32)[1], batch_iter(15840, 32)[0],validation_data=batch_iter2(15840,8)[1],validation_steps=batch_iter2(15840,8)[0], epochs=30,verbose=1,callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 学習履歴をプロット\n",
        "plot_history(history, '/content/drive/My Drive/kaggle_data/rireki1')\n",
        "\n",
        "###\n",
        "\n",
        "# 重みの保存\n",
        "model.save_weights('/content/drive/My Drive/kaggle_data/weight1/weights.6')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlaq8eZjpJMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xwSUrbHtpJ0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "6fa688ca-58cf-454e-d03f-4de47b5178a7"
      },
      "source": [
        "#1クラス\n",
        "\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import random\n",
        "from segmentation_models import Unet\n",
        "#from segmentation_models.backbones import get_preprocessing\n",
        "random.seed(1)\n",
        "\n",
        "cho=np.load(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/cho.npy\")\n",
        "cho=list(cho)\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train.csv\")\n",
        "sample_df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/sample_submission.csv\")\n",
        "\n",
        "classlabel=1\n",
        "\n",
        "#先頭番号\n",
        "a=[]\n",
        "#連続したラベル\n",
        "b=[]\n",
        "cho=[]\n",
        "index=0\n",
        "for i in range(3,7095-3):\n",
        "  a3=train_df.iat[i,0]\n",
        "  b3=train_df.iat[i+1,0]\n",
        "  c3=train_df.iat[i+2,0]\n",
        "  k3=[]\n",
        "  if a3!=b3 and b3==c3:\n",
        "    a.append(i)\n",
        "    k3.append(train_df.iat[i,1])\n",
        "    k3.append(train_df.iat[i,1])\n",
        "  elif b3==c3:\n",
        "    k3.append(train_df.iat[i,1])\n",
        "  elif a3==b3 and b3!=c3:\n",
        "    b.append(k3)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "#train_df(トレーニングデータフレーム)の特定の行(gyo)を入力とし、(クラスラベル,マスク行列)を出力、0がなにもない場所、1がひび割れ\n",
        "def mask(gyo):\n",
        "\ttrain=train_df.iat[gyo,2].split(\" \")\n",
        "\ttrain = [int(num) for num in train]\n",
        "\tmask = np.zeros(256*1600)\n",
        "\tmask=np.ravel(mask)\n",
        "\n",
        "\tfor i in range(int(len(train)/2)):\n",
        "\t\tmask[train[2*i]:train[2*i]+train[2*i+1]-1]=[1]*(train[2*i+1]-1)\n",
        "\tmask=mask.reshape(1600,256)\n",
        "\tmask=mask.T\n",
        "\tmask.reshape(256,1600)\n",
        "\tmask=np.array(mask)\n",
        "\treturn(train_df.iat[gyo,1],mask)\n",
        " \n",
        "\n",
        "#ランダム幾何変換関数\n",
        "def crop(A,B):\n",
        "  B0=B[0]\n",
        "  B1=B[1]\n",
        "  B2=B[2]\n",
        "  B3=B[3]\n",
        "  if random.choice([0, 1]) == 0:\n",
        "    A=cv2.flip(A,0)\n",
        "    B0=cv2.flip(B0,0)\n",
        "    B1=cv2.flip(B1,0)\n",
        "    B2=cv2.flip(B2,0)\n",
        "    B3=cv2.flip(B3,0)\n",
        "  else:\n",
        "    pass\n",
        "  if random.choice([0,1])==0:\n",
        "    A=cv2.flip(A,1)\n",
        "    B0=cv2.flip(B0,1)\n",
        "    B1=cv2.flip(B1,1)\n",
        "    B2=cv2.flip(B2,1)\n",
        "    B3=cv2.flip(B3,1)\n",
        "  else:\n",
        "    pass\n",
        "  rows,cols = A.shape\n",
        "  m1=random.choice(list(range(-5,5)))\n",
        "  m2=random.choice(list(range(-5,5)))\n",
        "  A = cv2.warpAffine(A,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B0 = cv2.warpAffine(B0,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B1 = cv2.warpAffine(B1,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B2 = cv2.warpAffine(B2,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  B3 = cv2.warpAffine(B3,np.float32([[1,0,m1],[0,1,m2]]),(cols,rows))\n",
        "  A=A*random.uniform(0.95, 1.05)\n",
        "  B=[B0,B1,B2,B3]\n",
        "  return(A,B)\n",
        "\n",
        "\n",
        "#XX入力YY出力データテンソルを作る場合のコード\n",
        "\"\"\"\n",
        "XX=[]\n",
        "YY=[]\n",
        "for i in range(データ数):\n",
        "\ty=mask(i)\n",
        "\timageid=train_df.iat[i,0]\n",
        "\tx = cv2.imread(\"C:/Users/victory adachi/pyworks/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid, cv2.IMREAD_GRAYSCALE)\n",
        "\t#x=np.array(Image.open(\"C:/Users/victory adachi/pyworks/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid))\n",
        "\tx=x/255\n",
        "\tx=np.reshape(x, (256,1600,1))\n",
        "\tX=x\n",
        "\tzeros=np.zeros([256,1600])\n",
        "\tY=[]\n",
        "\tfor j in range(4):\n",
        "\t\tif y[0]==j+1:\n",
        "\t\t\tY.append(y[1])\n",
        "\t\telse:\n",
        "\t\t\tY.append(zeros)\n",
        "\tY=np.stack(Y,2)\n",
        "\tXX.append(X)\n",
        "\tYY.append(Y)\n",
        "X_train=np.array(XX)\n",
        "Y_train=np.array(YY)\n",
        "\"\"\"\n",
        "\n",
        " \n",
        "#data generator にて入出力を作る場合のコード\n",
        "def batch_iter(data_size, batch_size):\n",
        "    data_size=int((4/5)*data_size)\n",
        "    num_batches_per_epoch = int(data_size / batch_size)\n",
        "\n",
        "    def data_generator():\n",
        "        while True:\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_index = batch_num * batch_size\n",
        "                k=random.sample(list(range(data_size)), len(list(range(data_size))) )\n",
        "                XX=[]\n",
        "                YY=[]\n",
        "                zeros=np.zeros([256,1600])\n",
        "                for i in range(batch_size):\n",
        "                \timageid=train_df.iat[k[i+start_index],0]\n",
        "\n",
        "                \ty=mask(k[i+start_index])\n",
        "                \tx = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid, cv2.IMREAD_GRAYSCALE)\n",
        "                \tx=x/255\n",
        "                \tY=[]\n",
        "                \tfor j in range(4):\n",
        "                \t\tif y[0]==j+1 and j+1==classlabel:\n",
        "                \t\t\tY.append(y[1])\n",
        "                \t\telse:\n",
        "                \t\t\tY.append(zeros)\n",
        "                \tx,Y=crop(x,Y)\n",
        "                \tx=np.reshape(x, (256,1600,1))\n",
        "                \tY=np.stack(Y,2)\n",
        "                \tif y[0]==classlabel:\n",
        "                \t  XX.append(x)\n",
        "                \t  YY.append(Y)\n",
        "                \telse:\n",
        "                \t  pass                     \n",
        "                \t#XX.append(x)\n",
        "                \t#YY.append(Y)\n",
        "                X_train=np.array(XX)\n",
        "                Y_train=np.array(YY)\n",
        "                yield X_train, Y_train\n",
        "    return num_batches_per_epoch, data_generator()\n",
        "#4:1で学習\n",
        "def batch_iter2(data_size, batch_size):\n",
        "    num_batches_per_epoch = int(data_size / (5*batch_size))\n",
        "    def data_generator2():\n",
        "        while True:\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_index = int((4*data_size)/5+batch_num * batch_size)\n",
        "                l0=[0]*(int((4*data_size)/5))\n",
        "                l=random.sample(list(range(int((4*data_size)/5),data_size)), len(list(range(int((4*data_size)/5),data_size))) )\n",
        "                l=l0+l\n",
        "                XX=[]\n",
        "                YY=[]\n",
        "                zeros=np.zeros([256,1600])\n",
        "                for i in range(batch_size):\n",
        "                \timageid=train_df.iat[l[i+start_index],0]\n",
        "                \ty=mask(l[i+start_index])\n",
        "                \tx = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid, cv2.IMREAD_GRAYSCALE)\n",
        "                \tx=x/255\n",
        "                \tY=[]\n",
        "                \tfor j in range(4):\n",
        "                \t\tif y[0]==j+1 and j+1==classlabel:\n",
        "                \t\t\tY.append(y[1])\n",
        "                \t\telse:\n",
        "                \t\t\tY.append(zeros)      \n",
        "                \tx,Y=crop(x,Y)\n",
        "                \tx=np.reshape(x, (256,1600,1))\n",
        "                \tY=np.stack(Y,2)\n",
        "                \tif y[0]==classlabel:\n",
        "                \t  XX.append(x)\n",
        "                \t  YY.append(Y)\n",
        "                \telse:\n",
        "                \t  pass                  \n",
        "                \t#XX.append(x)\n",
        "                \t#YY.append(Y)\n",
        "                X_train=np.array(XX)\n",
        "                Y_train=np.array(YY)\n",
        "                yield X_train, Y_train\n",
        "    return num_batches_per_epoch, data_generator2()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#履歴\n",
        "def plot_history(history, outdir):\n",
        "    # 精度の履歴をプロット\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['dice_coef'], marker='.')\n",
        "    plt.plot(history.history['val_dice_coef'], marker='.')\n",
        "    plt.title('model dice_coef')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('dice_coef')\n",
        "    plt.grid()\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "###\n",
        "    plt.savefig(os.path.join(outdir, 'dice_coef11.png'))\n",
        "    # 損失の履歴をプロット\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'], marker='.')\n",
        "    plt.plot(history.history['val_loss'], marker='.')\n",
        "    plt.title('model loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.grid()\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "###保存\n",
        "    plt.savefig(os.path.join(outdir, 'loss11.png'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#loss func\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#model\n",
        "def build_model(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (inputs)\n",
        "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (p1)\n",
        "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (p2)\n",
        "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (p3)\n",
        "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (p4)\n",
        "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (c5)\n",
        "    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
        "\n",
        "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (p5)\n",
        "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (c55)\n",
        "\n",
        "    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n",
        "    u6 = concatenate([u6, c5])\n",
        "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (u6)\n",
        "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (c6)\n",
        "\n",
        "    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "    u71 = concatenate([u71, c4])\n",
        "    c71 = Conv2D(32, (3, 3), activation='elu', padding='same') (u71)\n",
        "    c61 = Conv2D(32, (3, 3), activation='elu', padding='same') (c71)\n",
        "\n",
        "    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (u7)\n",
        "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (u8)\n",
        "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (u9)\n",
        "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (c9)\n",
        "\n",
        "    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = build_model((256, 1600, 1))\n",
        "\"\"\"\n",
        "# LOAD UNET WITH PRETRAINING FROM IMAGENET\n",
        "#preprocess = get_preprocessing('resnet34') # for resnet, img = (img-110.0)/1.0\n",
        "model = Unet('resnet34', input_shape=(128, 800, 3), classes=4, activation='sigmoid')\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
        "\n",
        "#モデルのサマリ\n",
        "#model.summary()\n",
        "#plot_model(model, show_shapes=True, to_file='result_steel/model.png')\n",
        "\n",
        "\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n",
        "             tf.keras.callbacks.ModelCheckpoint(\n",
        "                 '../data/temp/mnist_sequential_{epoch:03d}_{val_loss:.4f}.h5',\n",
        "                 save_best_only=True\n",
        "             )]\n",
        "\"\"\"\n",
        "#history=mod  el.fit(XX, YY, batch_size=128, epochs=7,validation_split=0.2, callbacks=callbacks)\n",
        "###\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'model11.h5', \n",
        "    monitor='val_dice_coef', \n",
        "    verbose=0, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='auto'\n",
        ")\n",
        "\n",
        "\n",
        "#学習開始\n",
        "history=model.fit_generator(batch_iter(7040, 160)[1], batch_iter(7040, 160)[0],validation_data=batch_iter2(7040,40)[1],validation_steps=batch_iter2(7040,40)[0], epochs=15,verbose=1,callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 学習履歴をプロット\n",
        "plot_history(history, '/content/drive/My Drive/kaggle_data/rireki1')\n",
        "\n",
        "###\n",
        "\n",
        "# 重みの保存\n",
        "model.save_weights('/content/drive/My Drive/kaggle_data/weight1/weights.11')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n",
            "Epoch 1/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:718: UserWarning: An input could not be retrieved. It could be because a worker has died.We do not have any information on the lost sample.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9471682bdf79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;31m#学習開始\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7040\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7040\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_iter2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7040\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_iter2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7040\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecw9llFY2Y34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ブラックアウト処理\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "train_df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train.csv\")\n",
        "\n",
        "def mask0(gyo):\n",
        "\ttrain=train_df.iat[gyo,2].split(\" \")\n",
        "\ttrain = [int(num) for num in train]\n",
        "\tmask = np.ones(256*1600)\n",
        "\tmask=np.ravel(mask)\n",
        "\n",
        "\tfor i in range(int(len(train)/2)):\n",
        "\t\tmask[train[2*i]:train[2*i]+train[2*i+1]-1]=[0]*(train[2*i+1]-1)\n",
        "\tmask=mask.reshape(1600,256)\n",
        "\tmask=mask.T\n",
        "\tmask.reshape(256,1600)\n",
        "\tmask=np.array(mask)\n",
        "\treturn(train_df.iat[gyo,1],mask)\n",
        "\n",
        "#id,ラベルを読み込んでidの重複箇所について、行番号シーケンスを得る。\n",
        "#行番号シーケンスから自分以外のマスクを得る。\n",
        "#idから画像を出力し、マスクをブラックアウト、保存。名前は\"1_gyo\"などとする\n",
        "\n",
        "cho=[]\n",
        "index=0\n",
        "for i in range(3,7095-3):\n",
        "  a=train_df.iat[i-3,0]\n",
        "  b=train_df.iat[i-2,0]\n",
        "  c=train_df.iat[i-1,0]\n",
        "  d=train_df.iat[i,0]\n",
        "  e=train_df.iat[i+1,0]\n",
        "  f=train_df.iat[i+2,0]\n",
        "  g=train_df.iat[i+3,0]\n",
        "  if a==d or b==d or c==d or e==d or f==d or g==d:\n",
        "    imageid=train_df.iat[i,0]\n",
        "    image = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+imageid, cv2.IMREAD_GRAYSCALE)\n",
        "    cho.append(i)\n",
        "    if a==d:\n",
        "      mask=mask0(i-3)[1]\n",
        "      image=image*mask\n",
        "    else:\n",
        "      pass\n",
        "    if b==d:\n",
        "      mask=mask0(i-2)[1]\n",
        "      image=image*mask\n",
        "    else:\n",
        "      pass\n",
        "    if c==d:\n",
        "      mask=mask0(i-1)[1]\n",
        "      image=image*mask\n",
        "    else:\n",
        "      pass\n",
        "    if e==d:\n",
        "      mask=mask0(i+1)[1]\n",
        "      image=image*mask\n",
        "    else:\n",
        "      pass\n",
        "    if f==d:\n",
        "      mask=mask0(i+2)[1]\n",
        "      image=image*mask\n",
        "    else:\n",
        "      pass\n",
        "    if g==d:\n",
        "      mask=mask0(i+3)[1]\n",
        "      image=image*mask\n",
        "    else:\n",
        "      pass\n",
        "    result = cv2.imwrite(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images2/\"+str(i)+\"_gyo.jpg\",image)\n",
        "  else:\n",
        "    pass\n",
        "cho=np.array(cho)\n",
        "np.save('/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/cho', cho)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPPnEpgv5lO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b132ca18-305a-42c6-ba18-57dc7dc714b2"
      },
      "source": [
        "\n",
        "#evaluation\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from segmentation_models import Unet\n",
        "train_df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train.csv\")\n",
        "\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "no=[0,362,726,1088]\n",
        "model = Unet('resnet34', input_shape=(256, 512, 3), classes=4, activation='sigmoid')\n",
        "model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n",
        "model.load_weights('/content/drive/My Drive/kaggle_data/weightlog/weight5model.h5')\n",
        "#, custom_objects={'bce_dice_loss': bce_dice_loss,'dice_coef':dice_coef})\n",
        "img = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train_images/\"+train_df.iat[514,0])\n",
        "img = [img[0:256,0:512] ,img[0:256,362:362+512],img[0:256,726:726+512],img[0:256,1088:1088+512]]\n",
        "\n",
        "#img=img.reshape(256,512,3)\n",
        "img = np.array(img)/255\n",
        "#X.append(img)\n",
        "X=np.array(img)\n",
        "pred = model.predict(X, batch_size=1, verbose=0)\n",
        "print(pred.shape)\n",
        "C=pred[0]\n",
        "C= C[:, :, 0] + C[:, :, 1] + C[:, :, 2]+ C[:, :, 3]\n",
        "plt.imshow(C)\n",
        "plt.show()\n",
        "C=pred[1]\n",
        "C= C[:, :, 0] + C[:, :, 1] + C[:, :, 2]+ C[:, :, 3]\n",
        "plt.imshow(C)\n",
        "plt.show()\n",
        "C=pred[2]\n",
        "C= C[:, :, 0] + C[:, :, 1] + C[:, :, 2]+ C[:, :, 3]\n",
        "plt.imshow(C)\n",
        "plt.show()\n",
        "C=pred[3]\n",
        "C= C[:, :, 0] + C[:, :, 1] + C[:, :, 2]+ C[:, :, 3]\n",
        "plt.imshow(C)\n",
        "plt.show()\n",
        "\n",
        "def mask2rle(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels= img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "def build_rles(masks):\n",
        "    width, height, depth = masks.shape\n",
        "    \n",
        "    rles = [mask2rle(masks[:, :, i])\n",
        "            for i in range(depth)]\n",
        "    \n",
        "    return rles\n",
        "B=np.zeros([256,1600])\n",
        "B=np.array([B,B,B,B])\n",
        "B=np.stack(B,2)\n",
        "B[0:256,0:512]=B[0:256,0:512]+np.where(pred[0] > 0.02, 1, 0)\n",
        "B[0:256,362:362+512]=B[0:256,362:362+512]+np.where(pred[1] > 0.02, 1, 0)\n",
        "B[0:256,726:726+512]=B[0:256,726:726+512]+np.where(pred[2] > 0.02, 1, 0)\n",
        "B[0:256,1088:1088+512]=B[0:256,1088:1088+512]+np.where(pred[3] > 0.02, 1, 0)\n",
        "B=np.where(B >= 1, 1, 0)\n",
        "print(build_rles(B))\n",
        "B= B[:, :, 0] + B[:, :, 1] + B[:, :, 2]+ B[:, :, 3]\n",
        "B=np.where(B >= 1, 1, 0)\n",
        "plt.imshow(B)\n",
        "plt.show()\n",
        "\n",
        "def mask(gyo):\n",
        "\ttrain=train_df.iat[gyo,2].split(\" \")\n",
        "\ttrain = [int(num) for num in train]\n",
        "\tmask = np.zeros(256*1600)\n",
        "\tmask=np.ravel(mask)\n",
        "\n",
        "\tfor i in range(int(len(train)/2)):\n",
        "\t\tmask[train[2*i]:train[2*i]+train[2*i+1]-1]=[1]*(train[2*i+1]-1)\n",
        "\tmask=mask.reshape(1600,256)\n",
        "\tmask=mask.T\n",
        "\tmask.reshape(256,1600)\n",
        "\tmask=np.array(mask)\n",
        "\treturn(train_df.iat[gyo,1],mask)\n",
        "mas=mask(514)[1]\n",
        "mas=mas.reshape(256,1600,1)\n",
        "print(build_rles(mas))\n",
        "mas=mas.reshape(256,1600)\n",
        "plt.imshow(mas)\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "for i in range(0, test_imgs.shape[0], 500):\n",
        "    batch_idx = list( range(i, min(test_imgs.shape[0], i + 500)) )\n",
        "\n",
        "    for j, b in tqdm(enumerate(batch_idx)):\n",
        "        filename = test_imgs['ImageId'].iloc[b]\n",
        "        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n",
        "        \n",
        "        pred_masks = batch_pred_masks[j, ].round().astype(int)\n",
        "        pred_rles = build_rles(pred_masks)\n",
        "        \n",
        "        image_df['EncodedPixels'] = pred_rles\n",
        "        test_df.append(image_df)\n",
        "\n",
        "test_df = pd.concat(test_df)\n",
        "test_df.drop(columns='ImageId', inplace=True)\n",
        "test_df.to_csv('submission.csv', index=False)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 256, 512, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['130817 1 223489 1 316673 1 409345 1', '', '256 1 92928 1 130817 1 131072 1 186112 1 223489 1 223744 1 278784 1 316673 1 316928 1 409345 1 409600 1', '']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAABYCAYAAAAOTbepAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAI/0lEQVR4nO3dbYxUZxnG8f+1u0Dd1vIiFbEQAUNM+KIgsZAaY8RSSpqiSWMgjaW1hkRr0moTA5KY+M2qabSJKSW2Bg32RdpaQjCkRb74QYTW8l5gbaksgVKaSBubKMjth/MMnK677CydmXP2yfVLJnvO85zdc++9c66dOXNmVxGBmZnlpavqAszMrPUc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGWpLuEtaIumwpD5Jq9uxDzMzG5pafZ27pG7gCHAT0A/sAlZExMGW7sjMzIbUjkfunwP6IuK1iPgP8CSwrA37MTOzIfS04WteDxwvrfcDNwzcSNIqYBVAN92f7eXaNpRiLSWQuogLF6quZFRQVxcRF8BvAm+O718jou4u3vnv22ci4rrB5tsR7k2JiPXAeoBrNSlu0KKqSrGRCEBVFzFKNELd/Wqe71/NuwAvsumNoabbcVrmBDC9tD4tjZmZWYe0I9x3AbMlzZQ0FlgObG7DfszMbAgtPy0TEeclfQfYBnQDj0fEgVbvx8zMhtaWc+4RsRXY2o6vbWZmw/M7VM3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMjRsuEuaLmmHpIOSDki6L41PkvSCpKPp48Q0LkkPS+qTtFfSvHZ/E2Zm9n7NPHI/DzwQEXOABcC9kuYAq4HtETEb2J7WAW4BZqfbKuCRlldtZmaXNWy4R8TJiHg5Lb8LHAKuB5YBG9JmG4CvpOVlwG+i8BdggqSpLa/czMyGNKJz7pJmAHOBncCUiDiZpk4BU9Ly9cDx0qf1p7GBX2uVpN2Sdp/j3yMs28zMLqfpcJd0DfAMcH9EvFOei4gAYiQ7joj1ETE/IuaPYdxIPtXMzIbRVLhLGkMR7Bsj4tk0/GbjdEv6eDqNnwCmlz59WhozM7MOaeZqGQGPAYci4qHS1GZgZVpeCTxfGr8zXTWzADhbOn1jZmYd0NPENjcCXwf2SXoljf0A+DHwtKR7gDeAr6W5rcBSoA94D7i7pRWbmdmwhg33iPgzoCGmFw2yfQD3fsC6zMzsA/A7VM3MMuRwNzPLkMPdzCxDDnczsww53M3MMlSLcFd3d9UljBpdvb2op5krWFtPPT109fZWsu8rVWXNVf6srlRXby8aM7aSfY/G+1eVuieMv+y8iisXqyXpXeBw1XU0YTJwpuoimuA6W2s01DkaagTX2WqfiIjrBpuoy8OKwxExv+oihiNpt+tsHdfZOqOhRnCdnVSL0zJmZtZaDnczswzVJdzXV11Ak1xna7nO1hkNNYLr7JhavKBqZmatVZdH7mZm1kIOdzOzDFUe7pKWSDosqU/S6grrmC5ph6SDkg5Iui+NT5L0gqSj6ePENC5JD6e690qa1+F6uyX9TdKWtD5T0s5Uz1OSxqbxcWm9L83P6GCNEyRtkvSqpEOSFtaxn5K+m37m+yU9IemqOvRT0uOSTkvaXxobcf8krUzbH5W0crB9taHOn6af+15Jz0maUJpbk+o8LOnm0nhbs2CwOktzD0gKSZPTemX9bJmIqOwGdAN/B2YBY4E9wJyKapkKzEvLHwaOAHOAnwCr0/hq4MG0vBT4I8Xful8A7Oxwvd8DfgdsSetPA8vT8jrgW2n528C6tLwceKqDNW4AvpmWxwIT6tZPin/e/jrwoVIf76pDP4EvAPOA/aWxEfUPmAS8lj5OTMsTO1DnYqAnLT9YqnNOOs7HATPT8d/diSwYrM40Ph3YRvFPhyZX3c+Wfb+V7hwWAttK62uANVU3JdXyPHATxTtnp6axqRRvuAJ4FFhR2v7idh2obRqwHfgSsCXdAc+UDqaLfU132oVpuSdtpw7UOD6FpgaM16qfFOF+PB2sPamfN9eln8CMAaE5ov4BK4BHS+Pv265ddQ6Y+yrF/1/+v2O80c9OZcFgdQKbgE8Dx7gU7pX2sxW3qk/LNA6shv40Vqn0VHsusBOYEpf+B+wpYEparrL2nwPfBy6k9Y8A/4yI84PUcrHONH82bd9uM4G3gF+n00e/knQ1NetnRJwAfgb8AzhJ0Z+XqF8/G0bavzocY9+geBTMZeqppE5Jy4ATEbFnwFSt6rwSVYd77Ui6BngGuD8i3inPRfGrutJrRyXdCpyOiJeqrKMJPRRPgR+JiLnAvyhOI1xUk35OBJZR/DL6OHA1sKTKmppVh/4NR9Ja4DywsepaBpLUS/H/oH9YdS3tUHW4n6A439UwLY1VQtIYimDfGBHPpuE3JU1N81OB02m8qtpvBG6TdAx4kuLUzC+ACZIafyuoXMvFOtP8eODtDtTZD/RHxM60voki7OvWzy8Dr0fEWxFxDniWosd162fDSPtX2TEm6S7gVuCO9IuIy9RTRZ2fpPilvicdT9OAlyV9rGZ1XpGqw30XMDtdmTCW4gWqzVUUIknAY8ChiHioNLUZaLwivpLiXHxj/M70qvoC4Gzp6XLbRMSaiJgWETMo+vWniLgD2AHcPkSdjfpvT9u3/dFeRJwCjkv6VBpaBBykZv2kOB2zQFJvug806qxVP0tG2r9twGJJE9OzlMVprK0kLaE4dXhbRLw3oP7l6aqjmcBs4K9UkAURsS8iPhoRM9Lx1E9xUcUpatbPK1L1SX+KV6WPULxSvrbCOj5P8RR3L/BKui2lOJ+6HTgKvAhMStsL+GWqex8wv4Kav8ilq2VmURwkfcDvgXFp/Kq03pfmZ3Wwvs8Au1NP/0BxdUHt+gn8CHgV2A/8luJKjsr7CTxB8TrAOYrguedK+kdxzrsv3e7uUJ19FOemG8fSutL2a1Odh4FbSuNtzYLB6hwwf4xLL6hW1s9W3fznB8zMMlT1aRkzM2sDh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGfofvjxQWclNhgkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['4291 4 4537 16 4784 27 5030 39 5277 50 5524 60 5770 72 6020 80 6272 86 6525 91 6778 95 7030 101 7283 106 7536 111 7788 117 8041 121 8294 124 8546 128 8799 131 9052 134 9304 138 9557 142 9810 145 10062 149 10315 152 10568 155 10820 159 11073 162 11326 165 11579 168 11832 171 12085 175 12338 178 12591 181 12844 184 13097 187 13349 191 13602 194 13855 197 14108 200 14361 203 14614 207 14867 210 15120 213 15373 216 15627 218 15883 218 16138 219 16394 219 16650 219 16905 220 17161 220 17417 221 17672 222 17928 222 18184 222 18439 223 18695 223 18950 224 19206 224 19462 224 19717 225 19973 226 20229 226 20484 227 20740 227 20996 227 21251 228 21507 228 21763 228 22019 228 22275 228 22531 229 22787 229 23043 229 23299 229 23555 229 23811 229 24067 229 24323 229 24579 229 24835 229 25091 230 25347 230 25603 230 25859 230 26115 230 26371 230 26627 230 26883 230 27139 230 27396 229 27652 229 27908 229 28164 229 28420 229 28676 229 28932 229 29188 228 29444 228 29700 228 29956 228 30212 228 30468 228 30724 228 30980 228 31236 228 31492 228 31748 228 32004 228 32260 228 32516 228 32772 228 33029 227 33285 227 33541 227 33797 227 34053 227 34309 227 34565 227 34821 226 35077 226 35333 226 35589 226 35845 226 36101 226 36357 226 36613 226 36869 226 37125 226 37381 226 37637 226 37893 226 38149 226 38405 226 38661 226 38917 226 39173 226 39429 226 39685 226 39941 226 40197 226 40453 225 40709 225 40965 225 41221 225 41477 225 41734 224 41990 224 42246 224 42502 224 42758 224 43014 224 43270 224 43526 224 43782 224 44038 224 44294 224 44550 224 44806 224 45062 224 45318 224 45574 224 45830 223 46086 223 46342 223 46598 223 46854 223 47110 223 47366 223 47622 223 47878 223 48134 223 48390 223 48646 223 48902 223 49158 223 49413 224 49669 224 49925 224 50181 224 50437 224 50693 224 50949 224 51205 224 51461 223 51717 223 51973 223 52229 223 52485 223 52741 223 52996 224 53252 224 53508 224 53764 224 54020 224 54276 224 54532 224 54788 224 55044 224 55300 224 55556 224 55812 224 56068 224 56324 224 56579 225 56835 225 57091 225 57347 225 57603 225 57859 225 58115 225 58371 225 58627 225 58883 225 59139 225 59395 225 59651 225 59907 225 60162 226 60418 226 60674 226 60930 226 61186 226 61442 226 61698 226 61954 226 62210 226 62466 225 62722 225 62978 225 63234 225 63490 225 63746 225 64002 225 64258 225 64514 225 64770 225 65026 225 65282 225 65538 225 65795 224 66051 224 66307 224 66563 224 66819 224 67075 224 67331 224 67587 224 67843 224 68099 224 68355 224 68611 224 68867 224 69123 224 69379 224 69635 224 69891 224 70147 224 70403 224 70659 224 70915 224 71171 224 71427 224 71683 224 71939 224 72195 224 72451 224 72707 224 72963 224 73219 224 73476 223 73732 223 73988 223 74244 223 74500 223 74756 223 75012 223 75268 223 75524 223 75780 223 76036 223 76292 223 76548 223 76804 223 77060 223 77316 223 77572 223 77828 223 78084 223 78340 223 78596 223 78852 222 79108 222 79364 222 79620 222 79876 222 80132 222 80388 222 80644 222 80900 222 81156 222 81411 223 81667 223 81923 223 82179 223 82435 223 82691 223 82947 223 83203 223 83459 223 83715 223 83971 223 84227 223 84483 223 84739 223 84995 223 85251 223 85507 223 85763 223 86019 223 86275 223 86531 223 86787 223 87043 223 87299 223 87555 223 87811 223 88067 223 88323 223 88579 223 88835 223 89091 223 89347 223 89602 224 89858 224 90114 224 90370 224 90626 224 90882 224 91138 224 91394 224 91650 224 91906 224 92162 224 92418 224 92674 224 92930 224 93186 224 93442 224 93698 224 93954 224 94210 224 94466 224 94722 224 94978 224 95234 224 95491 223 95747 223 96003 223 96259 223 96515 223 96771 223 97027 223 97283 223 97539 223 97795 223 98051 223 98307 223 98564 222 98820 222 99076 222 99332 222 99588 222 99844 222 100100 222 100356 223 100612 223 100868 223 101124 223 101380 223 101637 222 101893 222 102149 222 102405 222 102661 222 102917 222 103173 222 103429 222 103685 222 103941 222 104197 222 104453 222 104710 221 104966 221 105222 221 105478 221 105734 221 105990 221 106246 221 106502 221 106758 221 107014 221 107270 221 107526 221 107782 221 108038 221 108294 221 108550 221 108806 221 109062 221 109318 221 109573 222 109829 222 110085 222 110341 222 110597 222 110853 222 111109 222 111365 222 111621 222 111877 222 112133 222 112389 222 112645 222 112901 222 113157 222 113413 222 113669 222 113925 222 114181 222 114437 222 114693 222 114949 222 115205 222 115461 222 115717 222 115972 223 116228 223 116484 223 116740 223 116996 223 117252 222 117508 222 117764 222 118020 222 118276 222 118532 222 118788 222 119044 222 119300 222 119556 222 119812 222 120068 222 120324 222 120580 222 120836 222 121092 222 121348 222 121604 222 121860 222 122116 222 122371 223 122627 223 122883 223 123139 223 123395 223 123651 223 123907 223 124163 223 124419 223 124675 222 124931 222 125187 222 125443 222 125699 222 125955 222 126211 222 126467 222 126723 222 126979 222 127235 222 127491 222 127747 222 128003 222 128259 222 128515 222 128771 222 129027 222 129283 222 129540 221 129796 221 130052 221 130308 221 130564 221 130820 221 131076 221 131332 221 131588 221 131844 221 132100 220 132356 220 132612 220 132868 220 133124 220 133380 220 133636 220 133892 220 134148 220 134404 220 134660 220 134916 220 135172 220 135428 220 135684 220 135940 219 136196 217 136452 216 136708 215 136964 213 137221 211 137477 210 137733 208 137989 207 138245 205 138501 204 138757 203 139013 201 139269 200 139525 198 139781 197 140037 196 140293 194 140549 193 140805 192 141061 190 141317 189 141574 186 141830 185 142087 183 142343 181 142599 180 142856 178 143112 176 143368 175 143625 172 143881 171 144138 169 144394 167 144653 163 144914 157 145174 151 145435 145 145698 136 145962 127 146227 117 146491 107 146755 98 147020 87 147284 78 147547 70 147807 64 148067 59 148328 53 148588 47 148848 42 149109 35 149369 30 149629 25 149889 19 150150 13 150410 8 150670 2']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfor i in range(0, test_imgs.shape[0], 500):\\n    batch_idx = list( range(i, min(test_imgs.shape[0], i + 500)) )\\n\\n    for j, b in tqdm(enumerate(batch_idx)):\\n        filename = test_imgs['ImageId'].iloc[b]\\n        image_df = sub_df[sub_df['ImageId'] == filename].copy()\\n        \\n        pred_masks = batch_pred_masks[j, ].round().astype(int)\\n        pred_rles = build_rles(pred_masks)\\n        \\n        image_df['EncodedPixels'] = pred_rles\\n        test_df.append(image_df)\\n\\ntest_df = pd.concat(test_df)\\ntest_df.drop(columns='ImageId', inplace=True)\\ntest_df.to_csv('submission.csv', index=False)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qqrgYE-0sMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2acadaa-ef90-4f75-e2d2-9a3ca9409e26"
      },
      "source": [
        "import os\n",
        "\n",
        "# ファイル数を調べたいフォルダのパス\n",
        "path = \"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/test_images/\"\n",
        "\n",
        "# フォルダ内の全ファイル名をリスト化\n",
        "files = os.listdir(path)\n",
        "\n",
        "# リストの長さ（ファイル数）を取得\n",
        "count = len(files)\n",
        "\n",
        "# ファイル数を確認\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjGX2s7wu4fp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "d73c0254-f803-40b4-e15b-09b1f37d4d34"
      },
      "source": [
        "\n",
        "#evaluation\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "train_df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train.csv\")\n",
        "\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "test_df=pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/sample_submission.csv\")\n",
        "imageid=[]\n",
        "for i in range(len(test_df)):\n",
        "  for j in range(4):\n",
        "    imageid.append(test_df.iat[i,0]+\"_\"+str(j+1))\n",
        "encode=['']*len(imageid)\n",
        "df=pd.DataFrame({'ImageId_ClassId':imageid,'EncodedPixels':encode})\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def build_model(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (inputs)\n",
        "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (p1)\n",
        "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (p2)\n",
        "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (p3)\n",
        "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (p4)\n",
        "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (c5)\n",
        "    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
        "\n",
        "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (p5)\n",
        "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (c55)\n",
        "\n",
        "    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n",
        "    u6 = concatenate([u6, c5])\n",
        "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (u6)\n",
        "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (c6)\n",
        "\n",
        "    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "    u71 = concatenate([u71, c4])\n",
        "    c71 = Conv2D(32, (3, 3), activation='elu', padding='same') (u71)\n",
        "    c61 = Conv2D(32, (3, 3), activation='elu', padding='same') (c71)\n",
        "\n",
        "    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (u7)\n",
        "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (u8)\n",
        "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (u9)\n",
        "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (c9)\n",
        "\n",
        "    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = build_model((256, 1600, 1))\n",
        "\n",
        "\n",
        "def mask2rle(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels= img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "def build_rles(masks):\n",
        "    width, height, depth = masks.shape\n",
        "    \n",
        "    rles = [mask2rle(masks[:, :, i])\n",
        "            for i in range(depth)]\n",
        "    \n",
        "    return rles\n",
        "print(len(test_df))\n",
        "model.load_weights('/content/drive/My Drive/kaggle_data/weight1/weights.3')\n",
        "for i in range(len(test_df)):\n",
        "  img = cv2.imread(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/test_images/\"+test_df.iat[i,0], cv2.IMREAD_GRAYSCALE)\n",
        "  X=[]\n",
        "  img=img.reshape(256,1600,1)\n",
        "  img = np.array(img)/255\n",
        "  X.append(img)\n",
        "  X=np.array(X)\n",
        "  pred = model.predict(X, batch_size=1, verbose=0)\n",
        "  C=pred[0]\n",
        "  C=np.where(C >0.6, 1, 0)\n",
        "  C=build_rles(C)\n",
        "  for j in range(4):\n",
        "    df.iat[4*i+j,1]=C[j]\n",
        "  if i%200==0:\n",
        "    print(i)\n",
        "  else:\n",
        "    pass\n",
        "df.head()\n",
        "df.to_csv('/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/submission0.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5506\n",
            "0\n",
            "200\n",
            "400\n",
            "600\n",
            "800\n",
            "1000\n",
            "1200\n",
            "1400\n",
            "1600\n",
            "1800\n",
            "2000\n",
            "2200\n",
            "2400\n",
            "2600\n",
            "2800\n",
            "3000\n",
            "3200\n",
            "3400\n",
            "3600\n",
            "3800\n",
            "4000\n",
            "4200\n",
            "4400\n",
            "4600\n",
            "4800\n",
            "5000\n",
            "5200\n",
            "5400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVsJA5-CRpqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "3e802a34-c90f-4260-eede-019323311767"
      },
      "source": [
        "#evaluation\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/submission0.csv\")\n",
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId_ClassId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22019</th>\n",
              "      <td>fff4fd9bb.jpg_4</td>\n",
              "      <td>232247 2 232502 6 232758 7 233013 10 233268 12...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22020</th>\n",
              "      <td>fff598023.jpg_1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22021</th>\n",
              "      <td>fff598023.jpg_2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22022</th>\n",
              "      <td>fff598023.jpg_3</td>\n",
              "      <td>279813 4 280067 15 280323 28 280352 1 280571 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22023</th>\n",
              "      <td>fff598023.jpg_4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ImageId_ClassId                                      EncodedPixels\n",
              "22019  fff4fd9bb.jpg_4  232247 2 232502 6 232758 7 233013 10 233268 12...\n",
              "22020  fff598023.jpg_1                                                NaN\n",
              "22021  fff598023.jpg_2                                                NaN\n",
              "22022  fff598023.jpg_3  279813 4 280067 15 280323 28 280352 1 280571 3...\n",
              "22023  fff598023.jpg_4                                                NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-B10ElEqOZB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "e0bdf08c-b5f8-4f78-a5ba-730c05eba00d"
      },
      "source": [
        "#evaluation\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "train_df = pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/train.csv\")\n",
        "\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "test_df=pd.read_csv(\"/content/drive/My Drive/kaggle_data/severstal-steel-defect-detection/sample_submission.csv\")\n",
        "imageid=[]\n",
        "for i in range(len(test_df)):\n",
        "  for j in range(4):\n",
        "    imageid.append(test_df.iat[i,0]+\"_\"+str(j+1))\n",
        "encode=[np.nan]*len(imageid)\n",
        "df=pd.DataFrame({'ImageId_ClassId':imageid,'EncodedPixels':encode})\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId_ClassId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000f269f.jpg_1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000f269f.jpg_2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000f269f.jpg_3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000f269f.jpg_4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000ccc2ac.jpg_1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageId_ClassId  EncodedPixels\n",
              "0  0000f269f.jpg_1            NaN\n",
              "1  0000f269f.jpg_2            NaN\n",
              "2  0000f269f.jpg_3            NaN\n",
              "3  0000f269f.jpg_4            NaN\n",
              "4  000ccc2ac.jpg_1            NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyGf764COiYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 \"sec)\"}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bBXPmZ8URTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8-cfVieUcr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples/\n",
        "!cp cuda-samples/Common/* /usr/local/include"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUWhFG-PTnaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24hq8i8U_vDq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}